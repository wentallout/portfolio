---
title: The Art of Thinking Clearly (Part 3)
date: '2023-04-11'
categories:
    - 'psychology'
---


## Less is more (The Paradox of Choice)

I've counted and researched: my local grocery store stocks 48 varieties of
yogurt, 134 types of red wine, 64 different cleaning products and a grand total of
30,000 items. Amazon, the Internet bookseller, has two million titles available.

And yet, selection is the yardstick of progress. It is what sets us apart from
planned economies and the Stone Age. Yes, abundance makes you giddy, but
there is a limit. When it is exceeded, a surfeit of choices destroys quality of life.
The technical term for this is the **paradox of choice**.

In his book of the same title, psychologist Barry Schwartz describes why this is
so. First, a large selection leads to inner paralysis. To test this, a supermarket set
up a stand where customers could sample twenty-four varieties of jelly. They
could try as many as they liked and then buy them at a discount. The next day,
the owners carried out the same experiment with only six flavours. The result?
They sold ten times more jelly on day two. Why? With such a wide range,
customers could not come to a decision, so they bought nothing. The experiment
was repeated several times with different products. The results were always the
same.

Second, a broader selection leads to poorer decisions. If you ask young people
what is important in a life partner, they reel off all the usual qualities: intelligence, good manners, warmth, the ability to listen, a sense of humour and physical attractiveness. But do they actually take these criteria into account when choosing someone? In the past, a young man from a village of average size could
choose among maybe twenty girls of similar age with whom he went to school.

He knew their families and vice versa, leading to a decision based on several
well-known attributes. Nowadays, in the era of online dating, millions of potential
partners are at our disposal. It has been proven that the stress caused by this
mind-boggling variety is so large that the male brain reduces the decision to one
single criterion: physical attractiveness.

The consequences of this selection process you already know – perhaps even from personal experience.
Finally, large selection leads to discontent. How can you be sure you are
making the right choice when 200 options surround and confound you? The
answer is: you cannot. The more choice you have, the more unsure and therefore
dissatisfied you are afterward.

So, what can you do? Think carefully about what you want before you inspect existing offers. Write down these criteria and stick to them rigidly. Also, realise that you can never make a perfect decision. Aiming for this, given the flood of possibilities, is a form of irrational perfectionism. Instead, learn to love a ‘good'
choice. Yes, even in terms of life partners. Only the best will do? In this age of unlimited variety, rather the opposite is true: ‘good enough' is the new optimum(except, of course, for you and me).

## you like me, you really really like me (liking bias)

Kevin has just bought two boxes of fine Margaux. He rarely drinks wine – not even Bordeaux – but the sales assistant was so nice, not fake or pushy, just really
likeable. So he bought them.

Joe Girard is considered the most successful car salesman in the world. His tip
for success: ‘There's nothing more effective in selling anything than getting the
customer to believe, really believe, that you like him and care about him.' Girard
doesn't just talk the talk: his secret weapon is sending a card to his customers
each month. Just one sentence salutes them: ‘I like you.'

The liking bias is startlingly simple to understand and yet we continually fall
prey to it. It means this: the more we like someone, the more inclined we are to
buy from or help that person. Still, the question remains: what does ‘likeable'
even mean? According to research, we see people as pleasant if A) they are
outwardly attractive, B) they are similar to us in terms of origin, personality or
interests, and C) they like us. Consequently, advertising is full of attractive
people. Ugly people seem unfriendly and don't even make it into the background
(see A). In addition to engaging super-attractive types, advertising also employs
‘people like you and me' (see B) – those who are similar in appearance, accent or
background. In short, the more similar the better. Mirroring is a standard technique
in sales to get exactly this effect. Here, the salesperson tries to copy the gestures,
language, and facial expressions of his prospective client. 

If the buyer speaks very slowly and quietly, often scratching his head, it makes sense for the seller to
speak slowly and quietly, and to scratch his head now and then too. That makes
him likeable in the eyes of the buyer, and thus a business deal is more likely.

Finally, it's not unheard of for advertisers to pay us compliments: how many times
have you bought something ‘because you're worth it'? Here factor C comes into
play: we find people appealing if they like us. Compliments work wonders, even if
they ring hollow as a drum.

So-called multilevel marketing (selling through personal networks) works solely
because of the liking bias. Though there are excellent plastic containers in the
supermarket for a quarter of the price, Tupperware generates an annual turnover
of two billion dollars. Why? The friends who hold the Tupperware parties meet
the second and third congeniality standard perfectly.

Aid agencies employ the liking bias to great effect. Their campaigns use
beaming children or women almost exclusively. Never will you see a stone-faced,
wounded guerrilla fighter staring at you from billboards – even though he also
needs your support. Conservation organisations also carefully select who gets
the starring role in their advertisements. Have you ever seen a World Wildlife
Fund brochure filled with spiders, worms, algae or bacteria? They are perhaps
just as endangered as pandas, gorillas, koalas and seals – and even more
important for the ecosystem. But we feel nothing for them. The more human a
creature acts, the more similar it is to us, the more we like it. The bone skipper fly
is extinct? Too bad.

Politicians, too, are maestros of the liking bias. Depending on the make-up and
interests of an audience, they emphasise different topics, such as residential
area, social background or economic issues. And they flatter us: Each potential
voter is made to feel like an indispensable member of the team: ‘Your vote
counts!' Of course your vote counts, but only by the tiniest of fractions, bordering
on the irrelevant.

A friend who deals in oil pumps told me how he once closed an eight-figure
deal for a pipeline in Russia. ‘Bribery?' I inquired. He shook his head. ‘We were
chatting, and suddenly we got on to the topic of sailing. It turned out that both of
us – the buyer and me – were die-hard 470 dinghy fans. From that moment on, he
liked me; I was a friend. So the deal was sealed. Amiability works better than
bribery.'

So, if you are a salesperson, make buyers think you like them, even if this means outright flattery. And if you are a consumer, always judge a product independent of who is selling it. Banish the salespeople from your mind, or rather, pretend you don't like them.

## Don't cling to things (Endowment Effect)


The BMW gleamed in the parking lot of the used-car dealership. Although it had a
few miles on the odometer, it looked in perfect condition. I know a little about used
cars, and to me it was worth around $40,000. However, the salesman was
pushing for $50,000 and wouldn't budge a dime. When he called the next week to
say he would accept $40,000 after all, I went for it. The next day, I took it out for a
spin and stopped at a gas station. The owner came out to admire the car – and
proceeded to offer me $53,000 in cash on the spot. I politely declined. Only on the
way home did I realise how ridiculous I was to have said no. Something that I
considered worth $40,000 had passed into my possession and suddenly taken
on a value of more than $53,000. If I were thinking purely rationally, I would have
sold the car immediately. But, alas, I'd fallen under the influence of the
endowment effect. We consider things to be more valuable the moment we own
them. In other words, if we are selling something, we charge more for it than what
we ourselves would be willing to spend.

To probe this, psychologist Dan Ariely conducted the following experiment: in
one of his classes, he raffled tickets to a major basketball game, then polled the
students to see how much they thought the tickets were worth. The empty-handed
students estimated around $170, whereas the winning students would not sell
their ticket below an average of $2,400. The simple fact of ownership makes us
add zeros to the selling price.

In real estate, the endowment effect is palpable. Sellers become emotionally
attached to their houses and thus systematically overestimate their value. They
balk at the market price, expecting buyers to pay more – which is completely
absurd since this excess is little more than sentimental value.

We can safely say that we are better at collecting things than at casting them
off. Not only does this explain why we fill our homes with junk, but also why
lovers of stamps, watches and pieces of art part with them so seldomly.
Amazingly, the endowment effect affects not only possession but also nearownership.

Auction houses like Christie's and Sotheby's thrive on this. A person who bids until the end of an auction gets the feeling that the object is practically
theirs, thus increasing its value. The would-be owner is suddenly willing to pay
much more than planned, and any withdrawal from the bidding is perceived as a
loss – which defies all logic. In large auctions, such as those for mining rights or
mobile radio frequencies, we often observe the winner's curse: here, the
successful bidder turns out to be the economic loser when he gets caught up in the fervour and overbids.

There's a similar effect in the job market. If you are applying for a job and don't
get a call back, you have every reason to be disappointed. However, if you make
it to the final stages of the selection process and then receive the rejection, the
disappointment can be much bigger – irrationally. Either you get the job or you
don't; nothing else should matter.

In conclusion: don't cling to things. Consider your property something that the
‘universe' (whatever you believe this to be) has bestowed on you temporarily. Keep in mind that it can recoup this (or more) in the blink of an eye.

## THE INEVITABILITY OF UNLIKELY EVENTS: Coincidence

At 7.15p.m. on 1 March 1950, the fifteen members of the church choir in Beatrice,
Nebraska were scheduled to meet for rehearsal. For various reasons, they were
all running behind. The minister's family was delayed because his wife still had to
iron their daughter's dress. One couple was held back when their car wouldn't
start. The pianist wanted to be there 30 minutes early, but he fell into a deep
sleep after dinner. And so on. At 7.25p.m., the church exploded. The blast was
heard all around the village. It blew out the walls and sent the roof crashing to the
ground. Miraculously, nobody was killed. The fire chief traced the explosion back
to a gas leak, even though members of the choir were convinced they had
received a sign from God. Hand of God or coincidence?

Something last week made me think of my old school friend, Andy, whom I
hadn't spoken to in a long time. Suddenly the phone rang. I picked it up and, lo
and behold, it was Andy. ‘I must be telepathic!' I exclaimed excitedly. But,
telepathy or coincidence?

On 5 October 1990, the San Francisco Examiner reported that Intel would take
its rival, AMD, to court. Intel found out that the company was planning to launch a
computer chip named AM386, a term which clearly referred to Intel's 386 chip.
How Intel came upon the information is remarkable: by pure coincidence, both
companies had hired someone named Mike Webb. Both men were staying in the
same hotel in California, and checked out on the same day. After they had left, the
hotel accepted a package for Mike Webb at reception. It contained confidential
documents about the AM386 chip, and the hotel mistakenly sent it to Mike Webb
of Intel, who promptly forwarded the contents to the legal department.
How likely are stories like that? The Swiss psychiatrist C.G. Jung saw in them
the work of an unknown force, which he called synchronicity. But how should a
rationally minded thinker approach these accounts? Preferably with a piece of
paper and a pencil. Consider the first case, the explosion of the church. Draw four
boxes to represent each of the potential events. The first possibility is what
actually took place: ‘choir delayed and church exploded.' But there are three
other options: ‘choir delayed and church did not explode,' ‘choir on time and
church exploded' and ‘choir on time and church did not explode.' Estimate the
frequencies of these events and write them in the corresponding box. Pay special
attention to how often the last case has happened: every day, millions of choirs
gather for scheduled rehearsals and their churches don't blow up. Suddenly, the
story has lost its unimaginable quality. For all these millions of churches, it would
be improbable if something like what happened in Beatrice, Nebraska didn't take
place at least once a century. So, no: no hand of God. (And anyway, why would
God want to blow a church to smithereens? What a ridiculous way to
communicate with your worshippers!)

Let's apply the same thinking to the phone call. Keep in mind the many
occasions when ‘Andy' thinks of you but doesn't call; when you think of him and
he doesn't call; when you don't think of him and he calls; when he doesn't think of
you and you call?. . .?There is an almost infinite number of occasions when you
don't think of him and he doesn't call. But, since people spend about 90% of their
time thinking about others, it is not unlikely that, eventually, two people will think
of each other and one of them will pick up the phone. And it must not be just
Andy: if you have 100 other friends, the probability of this happening increases
greatly.

We tend to stumble when estimating probabilities. If someone says ‘never', I
usually register this as a minuscule probability greater than zero, since ‘never'
cannot be compensated by a negative probability.

In sum: let's not get too excited. Improbable coincidences are precisely that:
rare but very possible events. It's not surprising when they finally happen. What
would be more surprising would be if they never came to be.

## The Calamity of Conformity (Groupthink)

Have you ever bitten your tongue in a meeting? Surely. You sit there, say nothing
and nod along to proposals. After all, you don't want to be the (eternal) naysayer.
Moreover, you might not be 100% sure why you disagree, whereas the others are
unanimous – and far from stupid. So you keep your mouth shut for another day.
When everyone thinks and acts like this, groupthink is at work: this is where a
group of smart people makes reckless decisions because everyone aligns their
opinions with the supposed consensus. Thus, motions are passed that each
individual group member would have rejected if no peer pressure had been
involved. Groupthink is a special branch of social proof, a flaw that we discussed
in chapter 4.
In March 1960, the U.S. Secret Service began to mobilise anti-communist
exiles from Cuba, most of them living in Miami, to use against Fidel Castro's
regime. In January 1961, two days after taking office, President Kennedy was
informed about the secret plan to invade Cuba. Three months later, a key meeting
took place at the White House in which Kennedy and his advisers all voted in
favour of the invasion. On 17 April 1961, a brigade of 1,400 exiled Cubans landed
at the Bay of Pigs, on Cuba's south coast, with the help of the U.S. Navy, the Air
Force and the CIA. The aim was to overthrow Castro's government. However,
nothing went as planned. On the first day, not a single supply ship reached the
coast. The Cuban air force sank the first two and the next two turned around and
fled back to the U.S. A day later, Castro's army completely surrounded the
brigade. On the third day, the 1,200 survivors were taken into custody and sent to
military prisons. Kennedy's invasion of the Bay of Pigs is regarded as one of the
biggest flops in American foreign policy. That such an absurd plan was ever
agreed upon, never mind put into action, is astounding. All of the assumptions
that spoke in favour of invasion were erroneous. For example, Kennedy's team
completely underestimated the strength of Cuba's air force. Also, it was expected
that, in an emergency, the brigade would be able to hide in the Escambray
mountains and carry out an underground war against Castro from there. A glance
at the map shows that the refuge was 100 miles away from the Bay of Pigs, with
an insurmountable swamp in between. And yet, Kennedy and his advisers were
among the most intelligent people to ever run an American government. What
went wrong between January and April of 1961?
Psychology professor Irving Janis has studied many fiascos. He concluded that
they share the following pattern: members of a close-knit group cultivate team
spirit by (unconsciously) building illusions. One of these fantasies is a belief in
invincibility: ‘If both our leader [in this case, Kennedy] and the group are confident
that the plan will work, then luck will be on our side.' Next comes the illusion of
unanimity: if the others are of the same opinion, any dissenting view must be
wrong. No one wants to be the naysayer who destroys team unity. Finally, each
person is happy to be part of the group. Expressing reservations could mean
exclusion from it. In our evolutionary past, such banishment guaranteed death;
hence our strong urge to remain in the group's favour.
The business world is no stranger to groupthink. A classic example is the fate
of the world-class airline Swissair. Here, a group of highly paid consultants rallied
around the former CEO and, bolstered by the euphoria of past successes,
developed a high-risk expansion strategy (including the acquisition of several
European airlines). The zealous team built up such a strong consensus that even
rational reservations were suppressed, leading to the airline's collapse in 2001.
If you ever find yourself in a tight, unanimous group, you must speak your mind,
even if your team does not like it. Question tacit assumptions, even if you risk
expulsion from the warm nest. And, if you lead a group, appoint someone as
devil's advocate. She will not be the most popular member of the team, but she
might be the most important.

## Why you'll soon be playing megatrillions
Neglect of Probability
Two games of chance: in the first, you can win $10 million, and in the second,
$10,000. Which do you play? If you win the first game, it changes your life
completely: you can quit your job, tell your boss where to go and live off the
winnings. If you hit the jackpot in the second game, you can take a nice vacation
in the Caribbean, but you'll be back at your desk quick enough to see your
postcard arrive. The probability of winning is one in 100 million in the first game,
and one in 10,000 in the second game. So which do you choose?

Our emotions draw us to the first game, even though the second is ten times
better, objectively considered (expected win times probability). Therefore, the
trend is towards ever-larger jackpots – Mega Millions, Mega Billions, Mega
Trillions – no matter how small the odds are.

In a classic experiment from 1972, participants were divided into two groups.
The members of the first group were told that they would receive a small electric
shock. In the second group, subjects were told that the risk of this happening was
only 50%. The researchers measured physical anxiety (heart rate, nervousness,
sweating, etc.) shortly before commencing. The result were, well, shocking: there
was absolutely no difference. Participants in both groups were equally stressed.
Next, the researchers announced a series of reductions in the probability of a
shock for the second group: from 50% to 20%, then 10%, then 5%. The result: still
no difference! However, when they declared they would increase the strength of
the expected current, both groups' anxiety levels rose – again, by the same
degree. This illustrates that we respond to the expected magnitude of an event
(the size of the jackpot or the amount of electricity), but not to its likelihood. In
other words: we lack an intuitive grasp of probability.

The proper term for this is neglect of probability, and it leads to errors in
decision-making. We invest in start-ups because the potential profit makes dollar
signs flash before our eyes, but we forget (or are too lazy) to investigate the slim
chances of new businesses actually achieving such growth. Similarly, following
extensive media coverage of a plane crash, we cancel flights without really
considering the minuscule probability of crashing (which, of course, remains the
same before and after such a disaster). Many amateur investors compare their
investments solely on the basis of yield. For them, Google shares with a return of
20% must be twice as good as property that returns 10%. That's wrong. It would
be a lot smarter to also consider both investments' risks. But then again, we have
no natural feel for this so we often turn a blind eye to it.

Back to the experiment with the electric shocks: in group B, the probability of
getting a jolt was further reduced: from 5% to 4% to 3%. Only when the probability
reached zero did group B respond differently to group A. To us, 0% risk seems
infinitely better than a (highly improbable) 1% risk.
To test this, let's examine two methods of treating drinking water. Suppose a
river has two equally large tributaries. One is treated using method A, which
reduces the risk of dying from contaminated water from 5% to 2%. The other is
treated using method B, which reduces the risk from 1% to 0%, i.e. the threat is
completely eliminated. So, method A or B? If you think like most people, you will
opt for method B – which is silly because with measure A, 3% fewer people die,
and with B, just 1% fewer. Method A is three times as good! This fallacy is called
the zero-risk bias.
A classic example of this is the U.S. Food Act of 1958, which prohibits food that
contains cancer-causing substances. Instituted to achieve zero risk of cancer, this
ban sounds good at first, but it ended up leading to the use of more dangerous
(but non-carcinogenic) food additives. It is also absurd: as Paracelsus illustrated
in the sixteenth century, poisoning is always a question of dosage. Furthermore,
this law can never be enforced properly since it is impossible to remove the last
‘banned' molecule from food. Each farm would have to function like a hypersterile computer-chip factory, and the cost of food would increase a hundredfold.
Economically, zero risk rarely makes sense. One exception is when the
consequences are colossal, such as a deadly, highly contagious virus escaping
from a biotech laboratory.

We have no intuitive grasp of risk and thus distinguish poorly between different
threats. The more serious the threat and the more emotional the topic (such as
radioactivity), the less reassuring a reduction in risk seems to us. Two
researchers at the University of Chicago have shown that people are equally
afraid of a 99% chance as they are of a 1% chance of contamination by toxic
chemicals. An irrational response, but a common one.

## Scarcity Error

Coffee at a friend's house. We sat trying to make conversation while her three
children grappled with one another on the floor. Suddenly I remembered that I
had brought some glass marbles with me – a whole bag full. I spilled them out on
the floor, in the hope that the little angels would play with them in peace. Far from
it: a heated argument ensued. I didn't understand what was happening until I
looked more closely. Among the countless marbles there was just one blue one,
and the children scrambled for it. All the marbles were exactly the same size and
shiny and bright. But the blue one had an advantage over the others – it was one
of a kind. I had to laugh at how childish children are!

In August 2005, when I heard that Google would launch its own email service, I
was dead set on getting an account. (In the end I did.) At the time, new accounts
were very restricted and were given out only on invitation. This made me want
one even more. But why? Certainly not because I needed another email account
(back then, I already had four), nor because Gmail was better than the
competition, but simply because not everyone had access to it. Looking back, I
have to laugh at how childish adults are!

Rara sunt cara, said the Romans. Rare is valuable. In fact, the scarcity error is
as old as mankind. My friend with the three children is a part-time real-estate
agent. Whenever she has an interested buyer who cannot decide, she calls and
says ‘A doctor from London saw the plot of land yesterday. He liked it a lot. What
about you? Are you still interested?' The doctor from London – sometimes it's a
professor or a banker – is, of course, fictitious. The effect is very real, though: it
causes prospects to see the opportunity disappearing before their eyes, so they
act and close the deal. Why? This is the potential shortage of supply, yet again.
Objectively, this situation is incomprehensible: either the prospect wants the land
for the set price or he does not – regardless of any doctors from London.
To assess the quality of cookies, Professor Stephen Worchel split participants
into two groups. The first group received an entire box of cookies, and the second
group just two. In the end, the subjects with just two cookies rated the quality
much higher than the first group did. The experiment was repeated several times
and always showed the same result.
‘Only while stocks last,' the adverts alert. ‘Today only,' warn the posters.
Gallery owners take advantage of the scarcity error by placing red ‘sold' dots
under most of their paintings, transforming the remaining few works into rare
items that must be snatched up quickly. We collect stamps, coins, vintage cars
even when they serve no practical purpose. The post office doesn't accept the old
stamps, the banks don't take old coins, and the vintage cars are no longer
allowed on the road. These are all side issues; the attraction is that they are in
short supply.

In one study, students were asked to arrange ten posters in order of
attractiveness – with the agreement that afterward they could keep one poster as
a reward for their participation. Five minutes later, they were told that the poster
with the third highest rating was no longer available. Then they were asked to
judge all ten from scratch. The poster that was no longer available was suddenly
classified as the most beautiful. In psychology, this phenomenon is called
reactance: when we are deprived of an option, we suddenly deem it more
attractive. It is a kind of act of defiance. It is also known as the Romeo and Juliet
effect: because the love between the tragic Shakespearean teenagers is
forbidden, it knows no bounds. This yearning does not necessarily have to be a
romantic one; in the U.S., student parties are often littered with desperately drunk
teenagers – just because it's illegal to drink below the age of 21.

In conclusion: the typical response to scarcity is a lapse in clear thinking.
Assess products and services solely on the basis of their price and benefits. It
should be of no importance if an item is disappearing fast, nor if any doctors from
London take an interest.

## 28. Base-Rate Neglect
Mark is a thin man from Germany with glasses who likes to listen to Mozart.
Which is more likely? That Mark is A) a truck driver or B) a professor of literature
in Frankfurt. Most will bet on B, which is wrong. Germany has 10,000 times more
truck drivers than Frankfurt has literature professors. Therefore, it is more likely
that Mark is a truck driver. So what just happened? The detailed description
enticed us to overlook the statistical reality. Scientists call this fallacy base-rate
neglect: a disregard of fundamental distribution levels. It is one of the most
common errors in reasoning. Virtually all journalists, economists and politicians
fall for it on a regular basis.

Here is a second example: a young man is stabbed and fatally injured. Which
of these is more likely? A) The attacker is a Russian immigrant and imports
combat knives illegally, or B) the attacker is a middle-class American. You know
the drill now: option B is much more likely because there are a million times more
middle-class Americans than there are Russian knife importers.

In medicine, base-rate neglect plays an important role. For example, migraines
can point (among others) to a viral infection or a brain tumour. However, viral
infections are much more common (in other words, they have a higher base rate),
so doctors assess patients for these first before testing for tumours. This is very
reasonable. In medical school, residents spend a lot of time purging base-rate
neglect. The motto drummed into any prospective doctor in the United States is:
‘When you hear hoofbeats behind you, don't expect to see a zebra.' Which
means: investigate the most likely ailments before you start diagnosing exotic
diseases, even if you are a specialist in that.

Doctors are the only professionals who enjoy this base-rate training.
Regrettably, few people in business are exposed to it. Now and then I see highflying entrepreneurs' business plans and get very excited by their products, ideas
and personalities. I often catch myself thinking: this could be the next Google! But
a glance at the base rate brings me back down to earth. The probability that a firm
will survive the first five years is 20%. So what then is the probability that they will
grow into a global corporation? Almost zero. Warren Buffett once explained why
he does not invest in biotech companies: ‘How many of these companies make a
turnover of several hundred million dollars? It simply does not happen?. . .?The
most likely scenario is that these firms will just hover somewhere in the middle.'
This is clear base-rate thinking. For most people, survivorship bias (chapter 1) is
one of the causes for their base-rate neglect. They tend to see only the successful
individuals and companies, because the unsuccessful cases are not reported (or
are under-reported). This makes them neglect the large part of the 'invisible'
cases.

Imagine you are sampling wine in a restaurant and have to guess from which
country it comes. The label of the bottle is covered. If, like me, you are not a wine
connoisseur, the only lifeline you have is the base rate. You know from
experience that about three-quarters of the wines on the menu are of French
origin, so reasonably, you guess France, even if you suspect a Chilean or
Californian twist.

Sometimes I have the dubious honour of speaking in front of students of elite
business schools. When I ask them about their career prospects, most answer
that in the medium term, they see themselves on the boards of global companies.
Years ago, both my fellow students and I gave the same answer. The way I see it,
my role is to give students a base-rate crash course: ‘With a degree from this
school, the chance of you landing a spot on the board of a Fortune 500 company
is less than 0.1%. No matter how smart and ambitious you are, the most likely
scenario is that you will end up in middle management.' With this, I earn shocked
looks, and tell myself that I have made a small contribution toward mitigating their
future mid-life crises.

## Gambler's Fallacy

In the summer of 1913, something incredible happened in Monte Carlo. Crowds
gathered around a roulette table and could not believe their eyes. The ball had
landed on black twenty times in a row. Many players took advantage of the
opportunity and immediately put their money on red. But the ball continued to
come to rest on black. Even more people flocked to the table to bet on red. It had
to change eventually! But it was black yet again – and again and again. It was not
until the twenty-seventh spin that the ball eventually landed on red. By that time,
the players had bet millions on the table. In a few spins of the wheel, they were
bankrupt.

The average IQ of pupils in a big city is 100. To investigate this, you take a
random sample of 50 students. The first child tested has an IQ of 150. What will
the average IQ of your 50 students be? Most people guess 100. Somehow, they
think that the super-smart student will be balanced out – perhaps by a dismal
student with an IQ of 50 or by two below-average students with IQs of 75. But with
such a small sample, that is very unlikely. We must expect that the remaining 49
students will represent the average of the population, so they will each have an
average IQ of 100. Forty-nine times 100 plus one IQ of 150 gives us an average
of 101 in the sample.

The Monte Carlo example and the IQ experiment show that people believe in
the ‘balancing force of the universe'. This is the gambler's fallacy. However, with
independent events, there is no harmonising force at work: a ball cannot
remember how many times it has landed on black. Despite this, one of my friends
enters the weekly Mega Millions numbers into a spreadsheet, and then plays
those that have appeared the least. All this work is for naught. He is another
victim of the gambler's fallacy.

The following joke illustrates this phenomenon: a mathematician is afraid of
flying due to the small risk of a terrorist attack. So, on every flight he takes a bomb
with him in his hand luggage. ‘The probability of having a bomb on the plane is
very low,' he reasons, ‘and the probability of having two bombs on the same
plane is virtually zero!'

A coin is flipped three times and lands on heads on each occasion. Suppose
someone forces you to spend thousands of dollars of your own money betting on
the next toss. Would you bet on heads or tails? If you think like most people, you
will choose tails, although heads is just as likely. The gambler's fallacy leads us
to believe that something must change. 

A coin is tossed 50 times, and each time it lands on heads. Again, with
someone forcing you to bet, do you pick heads or tails? Now that you've seen an
example or two, you're wise to the game: you know that it could go either way.

But we've just come across another pitfall: the classic déformation
professionnelle (professional oversight) of mathematicians: common sense would
tell you that heads is the wiser choice, since the coin is obviously loaded.
Previously, we looked at regression to mean. An example: if you are
experiencing record cold where you live, it is likely that the temperature will return
to normal values over the next few days. If the weather functioned like a casino,
there would be a 50% chance that the temperature would rise and a 50% chance
that it would drop. But the weather is not like a casino. Complex feedback
mechanisms in the atmosphere ensure that extremes balance themselves out. In
other cases, however, extremes intensify. For example, the rich tend to get richer.
A stock that shoots up creates its own demand to a certain extent, simply because
it stands out so much – a sort of reverse compensation effect.

So, take a closer look at the independent and interdependent events around
you. Purely independent events really only exist at the casino, in the lottery and in
theory. In real life, in the financial markets and in business, with the weather and
your health, events are often interrelated. What has already happened has an
influence on what will happen. As comforting an idea as it is, there is simply no
balancing force out there for independent events. ‘What goes around, comes
around' simply does not exist.

## The Anchor

When was Abraham Lincoln born? If you don't know the year off the top of your
head, and your smartphone battery has just died, how do you answer this?
Perhaps you know that he was president during the Civil War in the 1860s and
that he was the first U.S. president to be assassinated. Looking at the Lincoln
Memorial in Washington, you don't see a young, energetic man but something
more akin to a worn-out 60-year-old veteran. The memorial must depict him at the
height of his political power, say at the age of 60. Let's assume that he was
assassinated in the mid-1860s, making 1805 our estimate for the year he was
born. (The correct answer is 1809.) So how did we work it out? We found an
anchor to help us – the 1860s – and worked from there to an educated guess.
Whenever we have to guess something – the length of the Mississippi River,
population density in Russia, the number of nuclear power plants in France – we
use anchors. We start with something we are sure of and venture into unfamiliar
territory from there. How else could we do it? Just pick a number off the top of our
heads? That would be irrational.

Unfortunately, we also use anchors when we don't need to. For example, one
day in a lecture, a professor placed a bottle of wine on the table. He asked his
students to write down the last two digits of their social security numbers and then
decide if they would be willing to spend that amount on the wine. In the auction
that followed, students with higher numbers bid nearly twice as much as students
with lower numbers. The social security digits worked as an anchor – albeit in a
hidden and misleading way.

The psychologist Amos Tversky conducted an experiment involving a wheel of
fortune. He had participants spin it, and afterward, they were asked how many
member states the United Nations has. Their guesses confirmed the anchor
effect: the highest estimates came from people who had spun high numbers on
the wheel.
Researchers Russo and Shoemaker asked students in what year Attila the Hun
suffered his crushing defeat in Europe. Just like the example with social security
numbers, the participants were anchored – this time with the last few digits of their
telephone number. The result? People with higher numbers chose later years
and vice versa. (If you were wondering, Attila's demise came about in 453.)
Another experiment: students and professional real-estate agents were given a
tour of a house and asked to estimate its value. Beforehand, they were informed
about a (randomly generated) listed sales price. As might be expected, the
anchor influenced the students: the higher this price, the higher they valued the
property. And the professionals? Did they value the house objectively? No, they
were similarly influenced by the random anchor amount. The more uncertain the
value of something – such as real estate, company stock or art – the more
susceptible even experts are to anchors.
Anchors abound, and we all clutch at them. The ‘recommended retail price'
printed on many products is nothing more than an anchor. Sales professionals
know they must establish a price at an early stage – long before they have an
offer. Also, it has been proven that if teachers know students' past grades, it
influences how they will mark new work. The most recent grades act as a starting
point.
In my early years, I had a quick stint at a consulting firm. My boss was a pro
when it came to using anchors. In his first conversation with any client, he made
sure to fix an opening price, which, by the way, almost criminally exceeded our
internal costs: ‘I'll tell you this now so you're not surprised when you receive the
quote, Mr. So-and-So: we've just completed a similar project for one of your
competitors and it was in the range of five million dollars.' The anchor was
dropped: the price negotiations started at exactly five million

